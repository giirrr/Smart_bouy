{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2F03rqE0ecPhEkImPvUAy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giirrr/first_ryun_project/blob/main/model_test_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00iwb59o2vJN"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import xgboost\n",
        "import lightgbm as lgb\n",
        "import catboost\n",
        "import ngboost\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from ngboost.learners import default_tree_learner\n",
        "from ngboost.distns import Normal\n",
        "from ngboost.scores import MLE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mlp\n",
        "import warnings\n",
        "import sklearn\n",
        "import joblib\n",
        "import os\n",
        "from random import randint\n",
        "\n",
        "from tqdm import tqdm\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\"\"\"data 불러오기\"\"\"\n",
        "df_test = pd.read_csv('./train_data/test_data.csv')\n",
        "\n",
        "df_test[df_test['AIR_PRESSURE'] < 900] = np.nan\n",
        "df_test[df_test['AIR_PRESSURE'] > 1100 ] = np.nan\n",
        "\n",
        "df_test[df_test['AIR_TEMPERATURE'] < -50] = np.nan\n",
        "df_test[df_test['AIR_TEMPERATURE'] > 70 ] = np.nan\n",
        "\n",
        "df_test[df_test['HUMIDITY'] < 0] = np.nan\n",
        "df_test[df_test['HUMIDITY'] > 100 ] = np.nan\n",
        "\n",
        "df_test[df_test['WIND_SPEED'] < 0] = np.nan\n",
        "df_test[df_test['WIND_SPEED'] > 80 ] = np.nan\n",
        "\n",
        "df_test = df_test.dropna()\n",
        "df_test.info()\n",
        "\n",
        "#MinMaxScaler 전처리\n",
        "df_test['AIR_PRESSURE'] = (lambda ap : (ap-900) / 200)(df_test['AIR_PRESSURE'])\n",
        "df_test['AIR_TEMPERATURE'] = (lambda at : (at+50) / 120)(df_test['AIR_TEMPERATURE'])\n",
        "df_test['day_min'] = (lambda dm : dm / 1439)(df_test['day_min'])\n",
        "df_test['HUMIDITY'] = (lambda h : h / 100)(df_test['HUMIDITY'])\n",
        "df_test['WIND_SPEED'] = (lambda ws : ws / 80)(df_test['WIND_SPEED'])\n",
        "#StandardScaler 전처리\n",
        "\n",
        "\n",
        "feature_cols = ['AIR_PRESSURE', 'AIR_TEMPERATURE', 'day_min', 'HUMIDITY', 'WIND_SPEED']\n",
        "label_cols = ['AIR_TEMPERATURE']\n",
        "\n",
        "y_test = df_test[label_cols].values\n",
        "X_test = df_test[feature_cols].values\n",
        "\n",
        "X_test = X_test[:-1]\n",
        "y_val = y_test[1:]\n",
        "\n",
        "XG_X_test = X_test.copy()\n",
        "LG_X_test = X_test.copy()\n",
        "CB_X_test = X_test.copy()\n",
        "NG_X_test = X_test.copy()\n",
        "CG_X_test = X_test.copy()\n",
        "\n",
        "\"\"\"model 불러오기\"\"\"\n",
        "xgb_model = xgboost.XGBRegressor()\n",
        "xgb_model.load_model(\"./learn_data/0epoch.json\")\n",
        "# xgb_model.load_model(\"./learn_data/0epoch11.json\")\n",
        "\"optuna 적용\"\n",
        "lgb_model = lgb.LGBMRegressor\n",
        "lgb_model = lgb.Booster(model_file='model1.txt')\n",
        "# lgb_model = lgb.Booster(model_file='model2.txt')\n",
        "\n",
        "cb_model = catboost.CatBoostRegressor()\n",
        "cb_model.load_model(\"./learn_data/0epoch2.json\")\n",
        "#cb_model.load_model(\"./learn_data/0epoch22.json\")\n",
        "\n",
        "#ngb_model = ngboost.NGBRegressor(n_estimators=200,  natural_gradient=True, learning_rate = 0.01, Base = default_tree_learner, Dist=Normal, Score=MLE, verbose_eval =50)\n",
        "ngb_model = joblib.load('./ngb_model.pkl')\n",
        "#xgboost.plot_importance(xgb_model)\n",
        "\n",
        "CG_model = keras.models.load_model('./learn_data/CGNN_tahn-Nadam-10dimention-LSTM/73-0.000050-0.00002.h5')\n",
        "\n",
        "\"\"\"model 불러오기 끝\"\"\"\n",
        "\n",
        "\n",
        "#non data [1074:1095]\n",
        "\n",
        "con_drop_length = [20,40,60,150,300,450,600]\n",
        "# con_drop_length = [20,40,60]\n",
        "\n",
        "fig_sv_sw = True\n",
        "\n",
        "mape_XG_space = np.zeros((len(con_drop_length), 1440))  ###################################\n",
        "mape_LG_space = np.zeros((len(con_drop_length), 1440))  ###################################\n",
        "mape_CB_space = np.zeros((len(con_drop_length), 1440))  ###################################\n",
        "mape_li_space = np.zeros((len(con_drop_length), 1440))  ##################################\n",
        "mape_ng_space = np.zeros((len(con_drop_length), 1440))  ##################################\n",
        "mape_CG_space = np.zeros((len(con_drop_length), 1440))  ##################################\n",
        "mape_flCG_space = np.zeros((len(con_drop_length), 1440))  ##################################\n",
        "\n",
        "for cdl in range(len(con_drop_length)):\n",
        "    tn = 1438 - con_drop_length[cdl]-2\n",
        "    \"\"\"현재 디렉토리에 있는 모든 파일 리스트를 가져와서 해당 파일 형식이 없으면 생성, 있으면 pass\"\"\"\n",
        "    if 'time_delta_{}'.format(con_drop_length[cdl]) in os.listdir():\n",
        "        pass\n",
        "    else:\n",
        "        os.mkdir('./time_delta_{}/'.format(con_drop_length[cdl]))\n",
        "    # for try_num in tqdm(range(3, tn)):\n",
        "    for try_num in tqdm(range(40)):\n",
        "        drop_point = random.randint(3,tn)\n",
        "        # drop_point = try_num   #continued drops start point 처음부터 끝까지(거의) 숫자 생성\n",
        "        XG_X_test[drop_point: drop_point + con_drop_length[cdl] - 1, 1] = np.nan   # 생성된 정수 + 결측갯수 만큼 nun값 처리\n",
        "        LG_X_test[drop_point: drop_point + con_drop_length[cdl] - 1, 1] = np.nan   # 생성된 정수 + 결측갯수 만큼 nun값 처리\n",
        "        CB_X_test[drop_point: drop_point + con_drop_length[cdl] - 1, 1] = np.nan   # 생성된 정수 + 결측갯수 만큼 nun값 처리\n",
        "        NG_X_test[drop_point: drop_point + con_drop_length[cdl] - 1, 1] = np.nan   # 생성된 정수 + 결측갯수 만큼 nun값 처리\n",
        "        CG_X_test[drop_point: drop_point + con_drop_length[cdl] - 1, 1] = np.nan   # 생성된 정수 + 결측갯수 만큼 nun값 처리\n",
        "        for i in range(1438):\n",
        "            X_test_li = X_test.copy()\n",
        "            # print(X_test_li[drop_point-1, 1])\n",
        "            # print(X_test_li[drop_point + con_drop_length[cdl], 1])\n",
        "            # print(np.linspace(X_test_li[drop_point-1, 1], X_test_li[drop_point + con_drop_length[cdl], 1], 22)[1:-1])\n",
        "            X_test_li[drop_point : drop_point + con_drop_length[cdl], 1] = np.linspace(X_test_li[drop_point-1, 1], X_test_li[drop_point + con_drop_length[cdl], 1], con_drop_length[cdl]+2)[1:-1]\n",
        "            if str(XG_X_test[i, 1]) == 'nan' or str(XG_X_test[i, 1]) == 'na':\n",
        "                XG_X_test[i, 1] = xgb_model.predict(np.expand_dims(XG_X_test[i - 1, :], axis=0))\n",
        "\n",
        "            if str(LG_X_test[i, 1]) == 'nan' or str(LG_X_test[i, 1]) == 'na':\n",
        "                LG_X_test[i, 1] = lgb_model.predict(np.expand_dims(LG_X_test[i - 1, :], axis=0))\n",
        "\n",
        "            if str(CB_X_test[i, 1]) == 'nan' or str(CB_X_test[i, 1]) == 'na':\n",
        "                CB_X_test[i, 1] = cb_model.predict(np.expand_dims(CB_X_test[i - 1, :], axis=0))\n",
        "\n",
        "            if str(NG_X_test[i, 1]) == 'nan' or str(NG_X_test[i, 1]) == 'na':\n",
        "                NG_X_test[i, 1] = ngb_model.predict(np.expand_dims(NG_X_test[i - 1, :], axis=0))\n",
        "\n",
        "            if str(CG_X_test[i, 1]) == 'nan' or str(CG_X_test[i, 1]) == 'na':\n",
        "                CG_X_test[i, 1] = CG_model.predict(np.expand_dims(CG_X_test[i - con_drop_length[cdl], :], axis=0))\n",
        "                #print(X_test[i-1, 1], XG_X_test[i-1, 1], LG_X_test[i-1, 1], CB_X_test[i-1, 1], NG_X_test[i-1, 1], CG_X_test[i-1, 1])\n",
        "\n",
        "            \"\"\"이미 그래프가 그려져있으면 pass 아니면 저장\"\"\"\n",
        "        if fig_sv_sw == True:\n",
        "\n",
        "            x_axis = np.arange(drop_point - 2, drop_point + con_drop_length[cdl] + 2)\n",
        "            ### 원본,예측값 전체\n",
        "            #fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            x = x_axis\n",
        "            y = ((y_val[drop_point - 3: drop_point + con_drop_length[cdl] + 1] * 120) - 50)\n",
        "            plt.plot(x, y, label='Actual')\n",
        "\n",
        "            #y2 = ((XG_X_test[drop_point - 2: drop_point + con_drop_length[cdl] + 2, 1] * 120) - 50)\n",
        "            #plt.plot(x, y2, label='XGBoosting_Predictionl')\n",
        "\n",
        "            #y3 = ((LG_X_test[drop_point - 2: drop_point + con_drop_length[cdl] + 2, 1] * 120) - 50)\n",
        "            #plt.plot(x, y3, label='LightGBM_Predictionl')\n",
        "\n",
        "            #y4 = ((CB_X_test[drop_point - 2: drop_point + con_drop_length[cdl] + 2, 1] * 120) - 50)\n",
        "            #plt.plot(x, y4, label='CatBoosting_Predictionl')\n",
        "\n",
        "            #y5 = ((NG_X_test[drop_point - 2: drop_point + con_drop_length[cdl] + 2, 1] * 120) - 50)\n",
        "            #plt.plot(x, y5, label='NGBoosting_Predictionl')\n",
        "\n",
        "            #y6 = (((CG_X_test[drop_point - 2: drop_point + con_drop_length[cdl] + 2, 1] ) * 120)-((CG_X_test[drop_point , 1]* 120)- (y_val[drop_point - 1 ]*120-50)))\n",
        "            y6 = (((CG_X_test[drop_point - 2: drop_point + con_drop_length[cdl] + 2, 1] ) * 120)-50)\n",
        "            plt.plot(x, y6, label='CGNN_Predictionl')\n",
        "\n",
        "           # y7 = (((((CG_X_test[drop_point - 2: drop_point + con_drop_length[cdl] + 2, 1]) * -1) + 1) * 120) - ((((CG_X_test[drop_point, 1] * -1) + 1) * 120) - (y_val[drop_point - 1] * 120 - 50)))\n",
        "            #plt.plot(x, y7, label='VL_CGNN_Predictionl')\n",
        "\n",
        "            y8 = ((X_test_li[drop_point - 2: drop_point + con_drop_length[cdl] + 2, 1] * 120) - 50)\n",
        "            plt.plot(x, y8, label='linear_Predictionl')\n",
        "            plt.legend()\n",
        "            plt.savefig('./time_delta_{0}/interpolate_graph_{1} to {2}'.format(con_drop_length[cdl], drop_point, drop_point + con_drop_length[cdl]))\n",
        "            plt.close()\n",
        "        else:\n",
        "            #y = ((y_val[drop_point - 1: drop_point + con_drop_length[cdl] + 1] * 120) - 50)\n",
        "            #y2 = ('XG : ', (XG_X_test[drop_point - 1: drop_point + con_drop_length[cdl] + 1, 1] * 120) - 50)\n",
        "            #y3 = ('LG : ', (LG_X_test[drop_point - 1: drop_point + con_drop_length[cdl] + 1, 1] * 120) - 50)\n",
        "            #y4 = ('CB : ', (CB_X_test[drop_point - 1: drop_point + con_drop_length[cdl] + 1, 1] * 120) - 50)\n",
        "            #y5 = ('NG : ', (NG_X_test[drop_point - 1: drop_point + con_drop_length[cdl] + 1, 1] * 120) - 50)\n",
        "            ##y6 = ('CG : ', (CG_X_test[drop_point - 1: drop_point + con_drop_length[cdl] + 1, 1] * 120) - 50)\n",
        "            #y7 = ('li : ', (X_test_li[drop_point - 1: drop_point + con_drop_length[cdl] + 1, 1] * 120) - 50)\n",
        "            #print(y)\n",
        "            #print(y2)\n",
        "            #print(y3)\n",
        "            #print(y4)\n",
        "            #print(y5)\n",
        "            ##print(y6)\n",
        "            #print(y7)\n",
        "            pass\n",
        "\n",
        "        \"\"\"XGB 보간 mape값 계산\"\"\"\n",
        "        XGP = XG_X_test[drop_point: drop_point + con_drop_length[cdl], 1]\n",
        "        XGP = np.delete(XGP, np.where(XGP == 0))\n",
        "        mape_XG = np.average(100 * np.abs((lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]) -\n",
        "                           (lambda at: (at * 120) - 50)(XGP))\n",
        "              / (lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]))\n",
        "\n",
        "        \"\"\"LGB 보간 mape값 계산\"\"\"\n",
        "        LGP = LG_X_test[drop_point: drop_point + con_drop_length[cdl], 1]\n",
        "        LGP = np.delete(LGP, np.where(LGP == 0))\n",
        "        mape_LG = np.average(100 * np.abs((lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]) -\n",
        "                                   (lambda at: (at * 120) - 50)(LGP))\n",
        "                      / (lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]))\n",
        "\n",
        "        \"\"\"CB 보간 mape값 계산\"\"\"\n",
        "        CGP = CB_X_test[drop_point: drop_point + con_drop_length[cdl], 1]\n",
        "        CGP = np.delete(CGP, np.where(CGP == 0))\n",
        "        mape_CB = np.average(\n",
        "            100 * np.abs((lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]) -\n",
        "                         (lambda at: (at * 120) - 50)(CGP))\n",
        "            / (lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]))\n",
        "\n",
        "        \"\"\"NG 보간 mape값 계산\"\"\"\n",
        "        NGP = NG_X_test[drop_point: drop_point + con_drop_length[cdl], 1]\n",
        "        NGP = np.delete(NGP, np.where(NGP == 0))\n",
        "        mape_NG = np.average(\n",
        "            100 * np.abs((lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]) -\n",
        "                         (lambda at: (at * 120) - 50)(NGP))\n",
        "            / (lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]))\n",
        "\n",
        "        \"\"\"fl_CGNN 보간 mape값 계산\"\"\"\n",
        "        fl_CGNP = ((((CG_X_test[drop_point - 2: drop_point + con_drop_length[cdl] + 2, 1] )*-1)+1)* 120)-((((CG_X_test[drop_point , 1]*-1)+1)* 120)- (y_val[drop_point - 1 ]*120-50))\n",
        "        fl_CGNP = np.delete(fl_CGNP, np.where(fl_CGNP == 0))\n",
        "        mape_flCG = np.average(\n",
        "            100 * np.abs((lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]) -\n",
        "                         (fl_CGNP))\n",
        "            / (lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]))\n",
        "\n",
        "        \"\"\"CGNN 보간 mape값 계산\"\"\"\n",
        "        CGNP = ((CG_X_test[drop_point - 2: drop_point + con_drop_length[cdl] + 2, 1] ) * 120)-((CG_X_test[drop_point , 1]* 120)- (y_val[drop_point - 1 ]*120-50))\n",
        "        CGNP = np.delete(CGNP, np.where(CGNP == 0))\n",
        "        mape_CG = np.average(\n",
        "            100 * np.abs((lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]) -\n",
        "                         (CGNP))\n",
        "            / (lambda at: (at * 120) - 50)(y_val[drop_point: drop_point + con_drop_length[cdl]]))\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"선형 보간 mape값 계산\"\"\"\n",
        "        mape_li = np.average(100 * np.abs((y_val[drop_point: drop_point + con_drop_length[cdl]]) -\n",
        "                          X_test_li[drop_point: drop_point + con_drop_length[cdl], 1])\n",
        "             / (y_val[drop_point: drop_point + con_drop_length[cdl]]))\n",
        "\n",
        "        \"\"\"만들어놓은 저장공간에 20,40,60 mape값 정리\"\"\"\n",
        "        mape_XG_space[cdl][try_num] = mape_XG\n",
        "        mape_LG_space[cdl][try_num] = mape_LG\n",
        "        mape_CB_space[cdl][try_num] = mape_CB\n",
        "        mape_ng_space[cdl][try_num] = mape_NG\n",
        "        mape_CG_space[cdl][try_num] = mape_CG\n",
        "        mape_flCG_space[cdl][try_num] = mape_flCG\n",
        "        mape_li_space[cdl][try_num] = mape_li\n",
        "\n",
        "        XG_X_test = X_test.copy()\n",
        "        LG_X_test = X_test.copy()\n",
        "        CB_X_test = X_test.copy()\n",
        "        NG_X_test = X_test.copy()\n",
        "        CG_X_test = X_test.copy()\n",
        "\n",
        "\n",
        "mape_mXG = []\n",
        "mape_mLG = []\n",
        "mape_mCB = []\n",
        "mape_mNG = []\n",
        "mape_mCG = []\n",
        "mape_mflCG = []\n",
        "mape_mli = []\n",
        "\n",
        "time_stamp = []\n",
        "for cd in con_drop_length:\n",
        "    time_stamp.append('time delta %d :'%cd)\n",
        "\n",
        "# np.savetxt('mape_XG_space.csv', mape_XG_space, delimiter=',')\n",
        "# np.savetxt('mape_LG_space.csv', mape_LG_space, delimiter=',')\n",
        "# np.savetxt('mape_CB_space.csv', mape_CB_space, delimiter=',')\n",
        "# np.savetxt('mape_ng_space.csv', mape_ng_space, delimiter=',')\n",
        "# np.savetxt('mape_CG_space.csv', mape_CG_space, delimiter=',')\n",
        "# np.savetxt('mape_flCG_space.csv', mape_flCG_space, delimiter=',')\n",
        "# np.savetxt('mape_li_space.csv', mape_li_space, delimiter=',')\n",
        "\n",
        "\"\"\"XGB,Linear 보간법 별 반복횟수 만큼 생성된 모델의 평균,분산값\"\"\"\n",
        "for i in range(len(con_drop_length)):\n",
        "    mape_mXG.append('XGBoost interpolate {0}\\u03bc={1: .5f} \\u03c3={2: .5f} '.format(time_stamp[i], np.average(mape_XG_space[i]), np.std(mape_XG_space[i])))\n",
        "    mape_mLG.append('LGBoost interpolate {0}\\u03bc={1: .5f} \\u03c3={2: .5f} '.format(time_stamp[i], np.average(mape_LG_space[i]), np.std(mape_LG_space[i])))\n",
        "    mape_mCB.append('CatGBoost interpolate {0}\\u03bc={1: .5f} \\u03c3={2: .5f} '.format(time_stamp[i], np.average(mape_CB_space[i]), np.std(mape_CB_space[i])))\n",
        "    mape_mNG.append('NGBoost interpolate {0}\\u03bc={1: .5f} \\u03c3={2: .5f} '.format(time_stamp[i], np.average(mape_ng_space[i]), np.std(mape_ng_space[i])))\n",
        "    mape_mCG.append('CGNN interpolate {0}\\u03bc={1: .5f} \\u03c3={2: .5f} '.format(time_stamp[i], np.average(mape_CG_space[i]), np.std(mape_CG_space[i])))\n",
        "    mape_mflCG.append('vertical_flip_CGNN interpolate {0}\\u03bc={1: .5f} \\u03c3={2: .5f} '.format(time_stamp[i], np.average(mape_flCG_space[i]), np.std(mape_flCG_space[i])))\n",
        "    mape_mli.append('linear interpolate {0}\\u03bc={1: .5f} \\u03c3={2: .5f}'.format(time_stamp[i], np.average(mape_li_space[i]), np.std(mape_li_space[i])))\n",
        "\n",
        "\"\"\"위의 값을 가지고 정규분포를 따르는지 히스토그램을 그려 확인(신뢰성)\"\"\"\n",
        "for j in range(len(con_drop_length)):\n",
        "    print('{}'.format(mape_mXG[j]))\n",
        "    print('{}'.format(mape_mLG[j]))\n",
        "    print('{}'.format(mape_mCB[j]))\n",
        "    print('{}'.format(mape_mNG[j]))\n",
        "    print('{}'.format(mape_mCG[j]))\n",
        "    print('{}'.format(mape_mflCG[j]))\n",
        "    print('{}\\n'.format(mape_mli[j]))\n",
        "#    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "#    plt.title('XGBoost_error(percent)_distribution')\n",
        "#    plt.hist(mape_XG_space[j], bins=100, histtype='stepfilled')\n",
        "#    plt.xticks(np.arange(0, np.max(mape_XG_space[j])+1, 0.5))\n",
        "#    plt.xlim(0, 5)\n",
        "#    plt.show()\n",
        "#\n",
        "#    plt.title('LGBoost_error(percent)_distribution')\n",
        "#    plt.hist(mape_LG_space[j], bins=100, histtype='stepfilled')\n",
        "#    plt.xticks(np.arange(0, np.max(mape_LG_space[j])+1, 0.5))\n",
        "#    plt.xlim(0, 5)\n",
        "#    plt.show()\n",
        "#\n",
        "#    plt.title('CatBoost_error(percent)_distribution')\n",
        "#    plt.hist(mape_CB_space[j], bins=100, histtype='stepfilled')\n",
        "#    plt.xticks(np.arange(0, np.max(mape_CB_space[j]) + 1, 0.5))\n",
        "#    plt.xlim(0, 5)\n",
        "#    plt.show()\n",
        "#\n",
        "#    plt.title('NGBoost_error(percent)_distribution')\n",
        "#    plt.hist(mape_ng_space[j], bins=100, histtype='stepfilled')\n",
        "#    plt.xticks(np.arange(0, np.max(mape_ng_space[j])+1, 0.5))\n",
        "#    plt.xlim(0, 5)\n",
        "#    plt.show()\n",
        "#\n",
        "#    #plt.title('CGNN_error(percent)_distribution')\n",
        "#    #plt.hist(mape_CG_space[j], bins=100, histtype='stepfilled')\n",
        "#    #plt.xticks(np.arange(0, np.max(mape_CG_space[j])+1, 0.5))\n",
        "#    #plt.xlim(0, 5)\n",
        "#    #plt.show()\n",
        "#\n",
        "#    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "#    plt.title('linear_error(percent)_distribution')\n",
        "#    plt.hist(mape_li_space[j], bins=100, histtype='stepfilled')\n",
        "#    plt.xticks(np.arange(0, np.max(mape_li_space[j]) + 1, 0.1))\n",
        "#    plt.xlim(0, 1)\n",
        "#    plt.show()"
      ]
    }
  ]
}