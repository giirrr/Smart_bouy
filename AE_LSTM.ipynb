{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlMPrDwV6uFh569LlHBb4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giirrr/first_ryun_project/blob/main/AE_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBNQskbCtvgb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mlp\n",
        "import warnings\n",
        "import sklearn\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import random\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import LSTM, Dropout, Dense, Activation, Conv1D, Flatten, Lambda, Reshape, concatenate, Input\n",
        "import datetime\n",
        "import seaborn as sb\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dropout,Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from keras import callbacks\n",
        "\n",
        "\"\"\"##전처리\"\"\"\n",
        "\n",
        "random.sample(range(120), 24)\n",
        "\n",
        "df_train = pd.read_csv('./data/master_data.csv')     # 7~8월\n",
        "df_test = pd.read_csv('./data/test_data.csv')        # 9월1일\n",
        "\n",
        "df_train[df_train['AIR_PRESSURE'] < 900] = np.nan\n",
        "df_train[df_train['AIR_PRESSURE'] > 1100 ] = np.nan\n",
        "\n",
        "df_train[df_train['AIR_TEMPERATURE'] < -50] = np.nan\n",
        "df_train[df_train['AIR_TEMPERATURE'] > 70 ] = np.nan\n",
        "\n",
        "df_train[df_train['HUMIDITY'] < 0] = np.nan\n",
        "df_train[df_train['HUMIDITY'] > 100 ] = np.nan\n",
        "\n",
        "df_train[df_train['WIND_SPEED'] < 0] = np.nan\n",
        "df_train[df_train['WIND_SPEED'] > 80 ] = np.nan\n",
        "\n",
        "df_test[df_test['AIR_PRESSURE'] < 900] = np.nan\n",
        "df_test[df_test['AIR_PRESSURE'] > 1100 ] = np.nan\n",
        "\n",
        "df_test[df_test['AIR_TEMPERATURE'] < -50] = np.nan\n",
        "df_test[df_test['AIR_TEMPERATURE'] > 70 ] = np.nan\n",
        "\n",
        "df_test[df_test['HUMIDITY'] < 0] = np.nan\n",
        "df_test[df_test['HUMIDITY'] > 100 ] = np.nan\n",
        "\n",
        "df_test[df_test['WIND_SPEED'] < 0] = np.nan\n",
        "df_test[df_test['WIND_SPEED'] > 80 ] = np.nan\n",
        "\n",
        "\"\"\"변동값 테스트\"\"\"\n",
        "# df_train['AIR_TEMPERATURE_delta'] = df_train['AIR_TEMPERATURE']-df_train['AIR_TEMPERATURE'].shift(1)\n",
        "# df_train['AIR_PRESSURE_delta'] = df_train['AIR_PRESSURE']-df_train['AIR_PRESSURE'].shift(1)\n",
        "# df_train['HUMIDITY_delta'] = df_train['HUMIDITY']-df_train['HUMIDITY'].shift(1)\n",
        "# df_train['WIND_SPEED_delta'] = df_train['WIND_SPEED']-df_train['WIND_SPEED'].shift(1)\n",
        "#\n",
        "# df_train[df_train['AIR_TEMPERATURE_delta']>(df_train['AIR_TEMPERATURE_delta'].mean()*2)] = np.nan\n",
        "# df_train[df_train['AIR_PRESSURE_delta']>(df_train['AIR_PRESSURE_delta'].mean()*2)] = np.nan\n",
        "# df_train[df_train['HUMIDITY_delta']>(df_train['HUMIDITY_delta'].mean()*2)] = np.nan\n",
        "# df_train[df_train['WIND_SPEED_delta']>(df_train['WIND_SPEED_delta'].mean()*2)] = np.nan\n",
        "#\n",
        "df_train = df_train.dropna()\n",
        "df_test = df_test.dropna()\n",
        "#df_train.info()\n",
        "#df_test.info()\n",
        "\n",
        "\n",
        "#MinMaxScaler 전처리\n",
        "df_train['AIR_PRESSURE'] = (lambda ap : (ap-900) / 200)(df_train['AIR_PRESSURE'])\n",
        "df_test['AIR_PRESSURE'] = (lambda ap : (ap-900) / 200)(df_test['AIR_PRESSURE'])\n",
        "df_train['AIR_TEMPERATURE'] = (lambda at : (at+50) / 120)(df_train['AIR_TEMPERATURE'])\n",
        "df_test['AIR_TEMPERATURE'] = (lambda at : (at+50) / 120)(df_test['AIR_TEMPERATURE'])\n",
        "df_train['day_min'] = (lambda dm : dm / 1439)(df_train['day_min'])\n",
        "df_test['day_min'] = (lambda dm : dm / 1439)(df_test['day_min'])\n",
        "df_train['HUMIDITY'] = (lambda h : h / 100)(df_train['HUMIDITY'])\n",
        "df_test['HUMIDITY'] = (lambda h : h / 100)(df_test['HUMIDITY'])\n",
        "df_train['WIND_SPEED'] = (lambda ws : ws / 80)(df_train['WIND_SPEED'])\n",
        "df_test['WIND_SPEED'] = (lambda ws : ws / 80)(df_test['WIND_SPEED'])\n",
        "#StandardScaler 전처리\n",
        "\n",
        "\n",
        "feature_cols = ['AIR_TEMPERATURE','AIR_PRESSURE', 'day_min', 'HUMIDITY', 'WIND_SPEED']\n",
        "label_cols = ['AIR_TEMPERATURE']\n",
        "\n",
        "y_train_df = df_train[label_cols].values\n",
        "X_train_df = df_train[feature_cols].values\n",
        "y_test_df = df_test[label_cols].values\n",
        "X_test_df = df_test[feature_cols].values\n",
        "\n",
        "xr_length = len(X_train_df[:-24])\n",
        "X_train = np.zeros((xr_length, 120))\n",
        "yr_length = len(y_train_df[:-24])\n",
        "y_train = np.zeros((yr_length, 25))\n",
        "\n",
        "for rl in range(xr_length):\n",
        "  X_train[rl] = X_train_df[rl:rl+24].reshape((120))\n",
        "  y_train[rl] = y_train_df[rl:rl+25].reshape((25))\n",
        "  for rs in random.sample(range(120), 24):\n",
        "    X_train[rl, rs] = 0\n",
        "\n",
        "xr_length = len(X_test_df[:-24])\n",
        "X_test = np.zeros((xr_length, 120))\n",
        "yr_length = len(y_test_df[:-24])\n",
        "y_test = np.zeros((yr_length, 25))\n",
        "\n",
        "for rl in range(xr_length):\n",
        "  X_test[rl] = X_test_df[rl:rl+24].reshape((120))\n",
        "  y_test[rl] = y_test_df[rl:rl+25].reshape((25))\n",
        "  for rs in random.sample(range(120), 24):\n",
        "    X_test[rl, rs] = 0\n",
        "\n",
        "\n",
        "\"\"\"##Model 쌓기\"\"\"\n",
        "\n",
        "input_size = 120\n",
        "\n",
        "input = Input(shape=(input_size))\n",
        "x = Dense(64, activation='sigmoid')(input)\n",
        "x = Dense(32, activation='sigmoid')(x)\n",
        "x = Reshape((32, 1))(x)\n",
        "x = LSTM(16, activation='sigmoid')(x)\n",
        "x = Dense(32, activation='sigmoid')(x)\n",
        "x = Dense(64, activation='sigmoid')(x)\n",
        "out = Dense(25, activation='sigmoid')(x)\n",
        "model = Model(input, [out], name='CGNN_cycle')\n",
        "\n",
        "model.compile(loss='msle',optimizer='Nadam')\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "if 'AE-LSTM' in os.listdir():\n",
        "    pass\n",
        "else:\n",
        "    os.mkdir('AE-LSTM')\n",
        "\n",
        "ep = 1000\n",
        "callbackz = [callbacks.ModelCheckpoint(\"./AE-LSTM/{loss:.8f}-{val_loss:.8f}-{epoch:04d}.h5\",\n",
        "                                       monitor=\"val_loss\",\n",
        "                                       save_best_only=False,\n",
        "                                       save_freq='epoch'\n",
        "                                       )]\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size = 16,\n",
        "                    validation_split=0.1,\n",
        "                    epochs=ep,\n",
        "                    callbacks=callbackz)\n",
        "\n",
        "# 7 훈련 과정 시각화 (손실)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('AE-LSTM Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\"\"\"##정확도\"\"\"\n",
        "\n",
        "train_acc = model.evaluate(X_train,y_train)\n",
        "test_acc = model.evaluate(X_test,y_test)\n",
        "\n",
        "print(train_acc)\n",
        "print(test_acc)\n",
        "\n",
        "print(y_test)\n",
        "print(y_test.shape)\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred)\n",
        "print(y_pred.shape)\n",
        "\n",
        "\"\"\"##점예측 시각화\"\"\"\n",
        "\n",
        "y_test2 =(lambda at : (at*120)-50)(y_test)\n",
        "\n",
        "y_pred2 =(lambda at : (at*120)-50)(y_pred)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 10), facecolor ='white')\n",
        "x = np.arange(len(y_pred))\n",
        "plt.title('AutoEncoder-LSTM')\n",
        "plt.plot(x, y_test2[:,-1], label= 'actual')\n",
        "plt.plot(x, y_pred2[:,-1], label= 'Prediction')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    }
  ]
}